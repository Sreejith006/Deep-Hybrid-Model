{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd0eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ./SingleHopLabelledReadings/SingleHopLabelledReadings/singlehop-indoor-moteid1-data.txt: [Errno 2] File Not Found. Check if PATH_TO_DATA_FOLDER is correct.\n",
      "Error processing ./SingleHopLabelledReadings/SingleHopLabelledReadings/singlehop-indoor-moteid2-data.txt: [Errno 2] File Not Found. Check if PATH_TO_DATA_FOLDER is correct.\n",
      "Error processing ./SingleHopLabelledReadings/SingleHopLabelledReadings/singlehop-outdoor-moteid3-data.txt: [Errno 2] File Not Found. Check if PATH_TO_DATA_FOLDER is correct.\n",
      "Error processing ./SingleHopLabelledReadings/SingleHopLabelledReadings/singlehop-outdoor-moteid4-data.txt: [Errno 2] File Not Found. Check if PATH_TO_DATA_FOLDER is correct.\n",
      "\n",
      "Total merged data points: 0\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SECTION 1: LIBRARY IMPORTS\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import os # Import os for path joining\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    MaxPooling1D,\n",
    "    Dropout,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    GlobalAveragePooling1D,\n",
    "    SeparableConv1D \n",
    ")\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "\n",
    "# Ensure reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# SECTION 2: DATA LOADING AND PREPROCESSING (CRITICAL PATH FIX)\n",
    "# ==============================================================================\n",
    "\n",
    "# ðŸ›‘ CRITICAL FIX: Update this path to match your local file structure ðŸ›‘\n",
    "# Example: If your .txt files are in './data/mote_readings/', set it to that.\n",
    "# The files are likely in a folder named 'SingleHopLabelledReadings' after unzipping.\n",
    "PATH_TO_DATA_FOLDER = '' \n",
    "\n",
    "# Base file names (the names of the .txt files)\n",
    "base_file_names = [\n",
    "    'singlehop-indoor-moteid1-data.txt',\n",
    "    'singlehop-indoor-moteid2-data.txt',\n",
    "    'singlehop-outdoor-moteid3-data.txt',\n",
    "    'singlehop-outdoor-moteid4-data.txt'\n",
    "]\n",
    "\n",
    "# Use os.path.join to create the correct, accessible file paths\n",
    "file_paths = [os.path.join(PATH_TO_DATA_FOLDER, name) for name in base_file_names]\n",
    "\n",
    "COLUMNS = ['Reading_Num', 'Mote_ID', 'Humidity', 'Temperature', 'Label']\n",
    "all_mote_data = []\n",
    "\n",
    "def load_and_clean_mote_data(file_path, skip_rows):\n",
    "    \"\"\"\n",
    "    Loads and cleans a single mote data file by skipping junk rows \n",
    "    and manually assigning the known columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load data\n",
    "        # sep=r'\\s+' handles both tabs and multiple spaces as delimiters\n",
    "        df = pd.read_csv(\n",
    "            file_path, \n",
    "            sep=r'\\s+',              \n",
    "            header=None,             \n",
    "            skiprows=skip_rows,      \n",
    "            engine='python',         \n",
    "            usecols=range(5),        \n",
    "            on_bad_lines='skip',\n",
    "            encoding='utf-8' \n",
    "        )\n",
    "        \n",
    "        # 2. MANUALLY ASSIGN THE CORRECT COLUMN NAMES (Ensures 'Label' exists)\n",
    "        df.columns = COLUMNS\n",
    "        \n",
    "        # 3. Robust type conversion and cleaning\n",
    "        for col in ['Reading_Num', 'Mote_ID', 'Label']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "        \n",
    "        for col in ['Humidity', 'Temperature']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # 4. Drop rows where critical data is missing\n",
    "        df.dropna(subset=['Mote_ID', 'Humidity', 'Temperature', 'Label'], inplace=True)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} rows from {os.path.basename(file_path)}\")\n",
    "        return df.astype({'Mote_ID': int, 'Label': int}) \n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # Re-raising a clear error for the user to see the path issue\n",
    "        print(f\"Error processing {file_path}: [Errno 2] File Not Found. Check if PATH_TO_DATA_FOLDER is correct.\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}. Data not included: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Mote-specific loading using the required skiprows for this dataset:\n",
    "# We iterate through the base_file_names and apply the correct skip rows\n",
    "skip_rules = {\n",
    "    'singlehop-indoor-moteid1-data.txt': 4,\n",
    "    'singlehop-indoor-moteid2-data.txt': 1,\n",
    "    'singlehop-outdoor-moteid3-data.txt': 1,\n",
    "    'singlehop-outdoor-moteid4-data.txt': 2\n",
    "}\n",
    "\n",
    "for file_name in base_file_names:\n",
    "    full_path = os.path.join(PATH_TO_DATA_FOLDER, file_name)\n",
    "    all_mote_data.append(load_and_clean_mote_data(full_path, skip_rules[file_name]))\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "merged_df = pd.concat(all_mote_data, ignore_index=True)\n",
    "\n",
    "# The rest of the code should now run successfully\n",
    "# ... (Sequence creation, model building, training, and evaluation) ...\n",
    "# ... (Continue with the code from the previous response from here) ...\n",
    "\n",
    "print(f\"\\nTotal merged data points: {len(merged_df)}\")\n",
    "if len(merged_df) > 0:\n",
    "    print(f\"Fault distribution:\\n{merged_df['Label'].value_counts(normalize=True).mul(100).round(2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
